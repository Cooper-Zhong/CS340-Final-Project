{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_my_bert = pd.read_csv('./submissions/my_kaggle_bert_submission.csv',index_col=0)\n",
    "df_kaggle_bert = pd.read_csv('./submissions/roberta-base-unbiased-small_submission.csv',index_col=0)\n",
    "df_roberta = pd.read_csv('./submissions/roberta-base-unbiased_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble = df_my_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble = df_ensemble.rename(columns={'my_kaggle_bert': 'my_ensemble'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "TOXICITY_COLUMN = 'target'\n",
    "def convert_to_bool(df, col_name):\n",
    "        df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "        \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns: # no target here\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "MODEL_NAME = 'my_ensemble'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_ensemble, (1,9):  0.9390518229855869\n",
      "my_ensemble, (2,8):  0.9399730032118785\n",
      "my_ensemble, (3,7):  0.9405413218732863\n",
      "my_ensemble, (4,6):  0.9407657662686624\n",
      "my_ensemble, (5,5):  0.940707910187318\n",
      "my_ensemble, (6,4):  0.9403374762724831\n",
      "my_ensemble, (7,3):  0.9396299820467724\n",
      "my_ensemble, (8,2):  0.9386360005759561\n"
     ]
    }
   ],
   "source": [
    "df_ensemble = convert_dataframe_to_bool(df_ensemble)\n",
    "for i in range(1, 9):\n",
    "    j = 10 - i \n",
    "\n",
    "    df_ensemble['my_ensemble'] = df_my_bert['my_kaggle_bert']*(0.1*i)+ df_roberta['roberta-base-unbiased']* (0.1*j)\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(df_ensemble, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "    bias_metrics_df.to_csv(f'./bias/{MODEL_NAME}_metrics.csv', index=False)\n",
    "    print(f'{MODEL_NAME}, ({i},{j}): ', get_final_metric(bias_metrics_df, calculate_overall_auc(df_ensemble, MODEL_NAME)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_ensemble, (1,1,8):  0.9400689916329782\n",
      "my_ensemble, (1,2,7):  0.9406993344621757\n",
      "my_ensemble, (1,3,6):  0.940892637429088\n",
      "my_ensemble, (1,4,5):  0.9408244918424135\n",
      "my_ensemble, (1,5,4):  0.9405152641043976\n",
      "my_ensemble, (1,6,3):  0.9399163932450181\n",
      "my_ensemble, (1,7,2):  0.9389391390069313\n",
      "my_ensemble, (2,1,7):  0.9408029898531265\n",
      "my_ensemble, (2,2,6):  0.9412302928213221\n",
      "my_ensemble, (2,3,5):  0.9413267934833698\n",
      "my_ensemble, (2,4,4):  0.9411575338826912\n",
      "my_ensemble, (2,5,3):  0.9406742633558489\n",
      "my_ensemble, (2,6,2):  0.9398650571556274\n",
      "my_ensemble, (3,1,6):  0.94120695794563\n",
      "my_ensemble, (3,2,5):  0.9414774677546471\n",
      "my_ensemble, (3,3,4):  0.9414415361901698\n",
      "my_ensemble, (3,4,3):  0.941116534803025\n",
      "my_ensemble, (3,5,2):  0.9404831787768949\n",
      "my_ensemble, (4,1,5):  0.941294769866587\n",
      "my_ensemble, (4,2,4):  0.9414082780731441\n",
      "my_ensemble, (4,3,3):  0.941202690504928\n",
      "my_ensemble, (4,4,2):  0.9407071110495272\n",
      "my_ensemble, (5,1,4):  0.9410535309191365\n",
      "my_ensemble, (5,2,3):  0.9410017553608554\n",
      "my_ensemble, (5,3,2):  0.9405931490801532\n",
      "my_ensemble, (6,1,3):  0.9405186623443444\n",
      "my_ensemble, (6,2,2):  0.9402753913360896\n",
      "my_ensemble, (7,1,2):  0.9396583012419342\n"
     ]
    }
   ],
   "source": [
    "df_ensemble = convert_dataframe_to_bool(df_ensemble)\n",
    "for i in range(1, 9):\n",
    "    for j in range(1, 9 - i):\n",
    "        k = 10 - i - j\n",
    "        df_ensemble['my_ensemble'] = df_my_bert['my_kaggle_bert']*(0.1*i) + df_kaggle_bert['roberta-base-unbiased-small']* (0.1*j) + df_roberta['roberta-base-unbiased']* (0.1*k)\n",
    "        bias_metrics_df = compute_bias_metrics_for_model(df_ensemble, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "        bias_metrics_df.to_csv(f'./bias/{MODEL_NAME}_metrics.csv', index=False)\n",
    "        print(f'{MODEL_NAME}, ({i},{j},{k}): ', get_final_metric(bias_metrics_df, calculate_overall_auc(df_ensemble, MODEL_NAME)))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick `df_ensemble` = df_my_bert['my_kaggle_bert']* `0.6` + df_roberta['roberta-base-unbiased']* `0.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_ensemble, (0.6,0.4):  0.9403374762724831\n"
     ]
    }
   ],
   "source": [
    "df_ensemble = convert_dataframe_to_bool(df_ensemble)\n",
    "df_ensemble['my_ensemble'] = df_my_bert['my_kaggle_bert']*0.6+ df_roberta['roberta-base-unbiased']* 0.4\n",
    "bias_metrics_df = compute_bias_metrics_for_model(df_ensemble, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "bias_metrics_df.to_csv(f'./bias/{MODEL_NAME}_metrics.csv', index=False)\n",
    "print(f'{MODEL_NAME}, ({0.6},{0.4}): ', get_final_metric(bias_metrics_df, calculate_overall_auc(df_ensemble, MODEL_NAME)))\n",
    "df_ensemble.to_csv('./submissions/my_ensemble_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
