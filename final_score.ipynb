{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'kaggle_bert'\n",
    "# MODEL_NAME = 'cnn'\n",
    "# MODEL_NAME = 'roberta-base-unbiased'\n",
    "# MODEL_NAME = 'roberta-base-unbiased-small'\n",
    "MODEL_LIST = ['cnn', 'roberta-base-unbiased-small', 'roberta-base-unbiased','kaggle_bert', 'my_kaggle_bert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all identities\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "TOXICITY_COLUMN = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bool(df, col_name):\n",
    "        df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "        \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns: # no target here\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn:  0.8811063685736299\n",
      "roberta-base-unbiased-small:  0.9336281439245725\n",
      "roberta-base-unbiased:  0.9374469355554393\n",
      "kaggle_bert:  0.9383775605488903\n",
      "my_kaggle_bert:  0.935123053682531\n"
     ]
    }
   ],
   "source": [
    "for MODEL_NAME in MODEL_LIST:\n",
    "    if os.path.exists(f'./bias/{MODEL_NAME}_metrics.csv'):\n",
    "        bias_metrics_df = pd.read_csv(f'./bias/{MODEL_NAME}_metrics.csv')\n",
    "        print(f'{MODEL_NAME}: ', get_final_metric(bias_metrics_df, calculate_overall_auc(eval_df, MODEL_NAME)))\n",
    "    else:    \n",
    "        eval_df = pd.read_csv(f'./submissions/{MODEL_NAME}_submission.csv')\n",
    "        if not os.path.exists(f'./submissions/{MODEL_NAME}_submission_plain.csv'):\n",
    "            submission = pd.DataFrame.from_dict({\n",
    "            'id': eval_df['id'],\n",
    "            'prediction': eval_df[MODEL_NAME]\n",
    "            })\n",
    "            submission.to_csv(f'./submissions/{MODEL_NAME}_submission_plain.csv', index=False)\n",
    "        eval_df = convert_dataframe_to_bool(eval_df)\n",
    "        bias_metrics_df = compute_bias_metrics_for_model(eval_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "        bias_metrics_df.to_csv(f'./bias/{MODEL_NAME}_metrics.csv', index=False)\n",
    "        print(f'{MODEL_NAME}: ', get_final_metric(bias_metrics_df, calculate_overall_auc(eval_df, MODEL_NAME)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
